{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTYLqpfcNo+dZeawgPBWZw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FazleRabbbiferdaus172/KNN-algorithm/blob/master/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7HUB4SlD0op",
        "colab_type": "code",
        "outputId": "21905e5d-f072-4e1d-b5be-7e057282513f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import numpy\n",
        "from numpy import genfromtxt\n",
        "import random\n",
        "import operator\n",
        "import itertools\n",
        "from collections import Counter \n",
        "\n",
        "def knn_cal(k,train_Set,some_set):\n",
        "    l_d = dict()\n",
        "    c_v = 0\n",
        "    for s in some_set:\n",
        "        for indi,v in enumerate(train_set):\n",
        "            sx = numpy.array(s[:len(s)-1])\n",
        "            vx = numpy.array(v[:len(v)-1])\n",
        "            ed = numpy.linalg.norm(sx - vx)\n",
        "            l_d[indi] = ed\n",
        "\n",
        "        l_d = {g: a for g, a in sorted(l_d.items(), key=lambda item: item[1])}\n",
        "        k_l_d = dict(itertools.islice(l_d.items(), k))\n",
        "        found_class_all, count = Counter(k_l_d.values()).most_common(1)[0]\n",
        "        found_class_list = [id for id,dt in k_l_d.items() if dt == found_class_all]\n",
        "        found_class_indi = found_class_list[0]\n",
        "        found_class = train_set[found_class_indi][-1] \n",
        "        if found_class == s[-1]:\n",
        "            c_v += 1\n",
        "    c_v_a = (c_v / len(some_set))*100\n",
        "    return c_v_a\n",
        "    \n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "data_path = '/content/gdrive/My Drive/Data_set/iris.csv'\n",
        "my_data = genfromtxt(data_path, delimiter=',')\n",
        "data = my_data.tolist()\n",
        "random.shuffle(data)\n",
        "train_set,val_set,test_set = [],[],[]\n",
        "for s in data:\n",
        "    r = random.uniform(0, 1)\n",
        "    if r >= 0 and r <= 0.7:\n",
        "        train_set.append(s)\n",
        "    elif r > 0.7 and r <= 0.85:\n",
        "        val_set.append(s)\n",
        "    else:\n",
        "        test_set.append(s)\n",
        "k = [1,3,5,10,15]\n",
        "f_rs = 0\n",
        "last_k = 0\n",
        "print(\"Value of k --------- Accuracy\")\n",
        "for i in k:\n",
        "    rs = knn_cal(int(i),train_set,val_set)\n",
        "    print('{} ------------------ {}'.format(i,rs))\n",
        "    if rs >= f_rs:\n",
        "        f_rs = rs\n",
        "        last_k = int(i)\n",
        "t_rs = knn_cal(last_k,train_set,test_set)\n",
        "print('Test accuracy :{}'.format(t_rs))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "value of k --------- Accuracy\n",
            "1 ------------------ 95.23809523809523\n",
            "3 ------------------ 95.23809523809523\n",
            "5 ------------------ 90.47619047619048\n",
            "10 ------------------ 90.47619047619048\n",
            "15 ------------------ 90.47619047619048\n",
            "test accuracy :100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO76b6fNO4qw",
        "colab_type": "code",
        "outputId": "89e5b86a-a38a-482d-c168-22f76a266fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import numpy\n",
        "from numpy import genfromtxt\n",
        "import random\n",
        "import operator\n",
        "import itertools\n",
        "\n",
        "def knn_cal(k,train_Set,some_set):\n",
        "    l_d = dict()\n",
        "    error = 0\n",
        "    for s in some_set:\n",
        "        for indi,v in enumerate(train_set):\n",
        "            sx = numpy.array(s[:len(s)-1])\n",
        "            vx = numpy.array(v[:len(v)-1])\n",
        "            ed = numpy.linalg.norm(sx - vx)\n",
        "            l_d[indi] = ed\n",
        "\n",
        "        l_d = {g: a for g, a in sorted(l_d.items(), key=lambda item: item[1])}\n",
        "        k_l_d = dict(itertools.islice(l_d.items(), k))\n",
        "        found_class_list = [id for id,dt in k_l_d.items()]\n",
        "        t_output = []\n",
        "        for i in found_class_list:\n",
        "            t_output.append(train_set[i][-1])\n",
        "        t_output = numpy.array(t_output)\n",
        "        avg = numpy.mean(t_output)\n",
        "        error = error + (s[-1] - avg)**2\n",
        "    m_s_r = error/len(some_set)\n",
        "    return m_s_r\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "data_path = '/content/gdrive/My Drive/Data_set/diabetes.csv'\n",
        "my_data = genfromtxt(data_path, delimiter=',')\n",
        "data = my_data.tolist()\n",
        "random.shuffle(data)\n",
        "train_set,val_set,test_set = [],[],[]\n",
        "for s in data:\n",
        "    r = random.uniform(0, 1)\n",
        "    if r >= 0 and r <= 0.7:\n",
        "        train_set.append(s)\n",
        "    elif r > 0.7 and r <= 0.85:\n",
        "        val_set.append(s)\n",
        "    else:\n",
        "        test_set.append(s)\n",
        "k = [1,3,5,10,15]\n",
        "f_rs = float('inf')\n",
        "last_k = 0\n",
        "print(\"Value of k --------- Mean squared error\")\n",
        "for i in k:\n",
        "    rs = knn_cal(int(i),train_set,val_set)\n",
        "    print('{} ------------------ {}'.format(i,rs))\n",
        "    if rs <= f_rs:\n",
        "        f_rs = rs\n",
        "        last_k = int(i)\n",
        "t_rs = knn_cal(last_k,train_set,test_set)\n",
        "print('Test Mean squared error :{}'.format(t_rs))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Value of k --------- Mean squared error\n",
            "1 ------------------ 5076.5\n",
            "3 ------------------ 5095.955938697319\n",
            "5 ------------------ 4939.053793103447\n",
            "10 ------------------ 4506.214137931035\n",
            "15 ------------------ 4325.815632183908\n",
            "Test Mean squared error :3655.871521367522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-jil11aMU4n",
        "colab_type": "code",
        "outputId": "42636db2-c9e9-4a7f-9adf-b1ede71c4361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "url = \"/content/gdrive/My Drive/Data_set/iris.csv\"\n",
        "names = ['A','B','C','D','E']\n",
        "dataset = pd.read_csv(url, names=names)\n",
        "dataset.head()\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, 4].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       0.88      0.93      0.90        15\n",
            "           2       0.93      0.87      0.90        15\n",
            "\n",
            "    accuracy                           0.93        45\n",
            "   macro avg       0.93      0.93      0.93        45\n",
            "weighted avg       0.93      0.93      0.93        45\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}